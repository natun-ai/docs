"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[3298],{4907:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>h});var o=n(9953);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,o,r=function(e,t){if(null==e)return{};var n,o,r={},a=Object.keys(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=o.createContext({}),c=function(e){var t=o.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},d=function(e){var t=c(e.components);return o.createElement(s.Provider,{value:t},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},m=o.forwardRef((function(e,t){var n=e.components,r=e.mdxType,a=e.originalType,s=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),p=c(n),m=r,h=p["".concat(s,".").concat(m)]||p[m]||u[m]||a;return n?o.createElement(h,i(i({ref:t},d),{},{components:n})):o.createElement(h,i({ref:t},d))}));function h(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var a=n.length,i=new Array(a);i[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[p]="string"==typeof e?e:r,i[1]=l;for(var c=2;c<a;c++)i[c]=n[c];return o.createElement.apply(null,i)}return o.createElement.apply(null,n)}m.displayName="MDXCreateElement"},2614:(e,t,n)=>{n.d(t,{Z:()=>k});var o=n(9953),r=n(4923),a=n(9622),i=n(7980),l=n(2755),s=n(261);const c="cardContainer__Cxy",d="cardTitle_gSLP",p="cardDescription_q2be";function u(e){let{href:t,children:n}=e;return o.createElement(a.Z,{href:t,className:(0,r.Z)("card padding--lg",c)},n)}function m(e){let{href:t,icon:n,title:a,description:i}=e;return o.createElement(u,{href:t},o.createElement("h2",{className:(0,r.Z)("text--truncate",d),title:a},n," ",a),i&&o.createElement("p",{className:(0,r.Z)("text--truncate",p),title:i},i))}function h(e){let{item:t}=e;const n=(0,i.Wl)(t);return n?o.createElement(m,{href:n,icon:"\ud83d\uddc3\ufe0f",title:t.label,description:(0,s.I)({message:"{count} items",id:"theme.docs.DocCard.categoryDescription",description:"The default description for a category card in the generated index about how many items this category includes"},{count:t.items.length})}):null}function f(e){let{item:t}=e;const n=(0,l.Z)(t.href)?"\ud83d\udcc4\ufe0f":"\ud83d\udd17",r=(0,i.xz)(t.docId??void 0);return o.createElement(m,{href:t.href,icon:n,title:t.label,description:r?.description})}function g(e){let{item:t}=e;switch(t.type){case"link":return o.createElement(f,{item:t});case"category":return o.createElement(h,{item:t});default:throw new Error(`unknown item type ${JSON.stringify(t)}`)}}function k(e){let{docId:t}=e;try{const e=(0,i.xz)(t??void 0),n=t.toLowerCase().endsWith("/readme")?t.substring(0,t.length-"/readme".length):t;return o.createElement("p",null,o.createElement(g,{item:{type:"link",label:e.title,docId:t,href:"/"+n}}))}catch(n){return o.createElement("div",{className:"card padding--lg cardContainer margin-bottom--sm"},o.createElement("b",null,"Error:")," ",n.message)}}},7138:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>l,default:()=>u,frontMatter:()=>i,metadata:()=>s,toc:()=>d});var o=n(1943),r=(n(9953),n(4907)),a=n(2614);const i={id:"readme",sidebar_position:0,sidebar_label:"Introduction",title:"Introduction"},l=void 0,s={unversionedId:"docs/readme",id:"docs/readme",title:"Introduction",description:"What is Raptor?",source:"@site/docs/docs/README.md",sourceDirName:"docs",slug:"/docs/",permalink:"/docs/",draft:!1,editUrl:"https://github.com/raptor-ml/docs/tree/master/docs/docs/README.md",tags:[],version:"current",sidebarPosition:0,frontMatter:{id:"readme",sidebar_position:0,sidebar_label:"Introduction",title:"Introduction"},sidebar:"docs",next:{title:"Getting Started",permalink:"/docs/getting-started-ipynb"}},c={},d=[{value:"What is Raptor?",id:"what-is-raptor",level:2},{value:"What does it solve?",id:"what-does-it-solve",level:2},{value:"Ready to dive in?",id:"ready-to-dive-in",level:2},{value:"How does it work?",id:"how-does-it-work",level:2},{value:"Quick Example",id:"quick-example",level:2},{value:"What&#39;s next?",id:"whats-next",level:2}],p={toc:d};function u(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,o.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"what-is-raptor"},"What is Raptor?"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/raptor-ml/raptor"},"Raptor")," is an open-source tool that enables data scientists and ML engineers to\nbuild and deploy operational models and ML-driven functionality, without learning backend engineering."),(0,r.kt)("p",null,"With Raptor, you can export your Python research code as standard production artifacts, and deploy them to Kubernetes.\nOnce you deployed, Raptor optimize data processing and feature calculation for production, deploy models to Sagemaker or\nDocker containers, connect to your production data sources, scaling, high availability, caching, monitoring, and all\nother backend concerns."),(0,r.kt)("h2",{id:"what-does-it-solve"},"What does it solve?"),(0,r.kt)("p",null,'Without Raptor, data scientists and ML engineers have to learn backend engineering and to build the "production-version"\nof their work: connect the data sources, transform the data with Flink/Spark or even Java, write the deployment code,\ndockerize the model, handle the scaling, and so on.'),(0,r.kt)("p",null,"This is a lot of work, and it's not the core value of the data scientist or ML engineer - so many models are not being\ndeployed to be part of the product, or are waiting upon backend engineers to be built."),(0,r.kt)("p",null,"Raptor changes the game."),(0,r.kt)("p",null,(0,r.kt)("img",{parentName:"p",src:"/img/simplified-high-level.png",alt:"High-level solution"})),(0,r.kt)("p",null,"With Raptor, you can export your Python research code as standard production artifacts, that follows the market's best\npractices, and ship to production. Raptor will take care of the rest."),(0,r.kt)("p",null,"It let you ",(0,r.kt)("strong",{parentName:"p"},"unleash your creativity, and focus on your real work")," - building models and ML-driven functionality in\nreal\nproducts."),(0,r.kt)("h2",{id:"ready-to-dive-in"},"Ready to dive in?"),(0,r.kt)("p",null,"Jump right in, and build your first Proof-of-Concept in less than 5 minutes:"),(0,r.kt)("div",{class:"row"},(0,r.kt)("div",{class:"col col--6"},(0,r.kt)(a.Z,{docId:"docs/getting-started-ipynb",mdxType:"DocCard"})),(0,r.kt)("div",{class:"col col--6"},(0,r.kt)(a.Z,{docId:"docs/concepts/README",mdxType:"DocCard"}))),(0,r.kt)("h2",{id:"how-does-it-work"},"How does it work?"),(0,r.kt)("p",null,"Raptor lets you develop your features and models in Python, and export them to production. After you export your work,\nRaptor will take care of the rest - it will optimize your code for production, connect to your production data sources,\nbuild and run your production data pipelines, deploy your models to Model Servers, scale, monitor, and so on."),(0,r.kt)("p",null,'We call this process "exporting to production", and it\'s the core of Raptor.'),(0,r.kt)("p",null,(0,r.kt)("img",{parentName:"p",src:"/assets/feature-def.png",alt:"How it works"})),(0,r.kt)("p",null,'To achieve this, you need to write your code in "the Raptor way", and use Raptor\'s decorators to mark your complex\nparts. This allows us to translate it later on, and to optimize it for production.'),(0,r.kt)("p",null,"To learn more ",(0,r.kt)("a",{parentName:"p",href:"/reference/how-does-raptor-work"},"how does Raotor work"),', and how to write your code in "the Raptor way",\nread the ',(0,r.kt)("a",{parentName:"p",href:"/reference/how-does-raptor-work"},'"How does Raptor work?"')," section and the ",(0,r.kt)("a",{parentName:"p",href:"/docs/concepts/"},'"Concepts"'),"\nsection."),(0,r.kt)("h2",{id:"quick-example"},"Quick Example"),(0,r.kt)("p",null,"The following example shows you a relatively simple example that's for the sake of demonstration. It's not a real-world\nexample, but it will give you a good idea of how your work will look like."),(0,r.kt)("p",null,"First, install the LabSDK:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"pip install --upgrade raptor-labsdk\n")),(0,r.kt)("p",null,"Then, create a new file called ",(0,r.kt)("inlineCode",{parentName:"p"},"hello_world.py"),", or open your Notebook and write the following code:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:"showLineNumbers",showLineNumbers:!0},"import pandas as pd\nfrom raptor import *\nfrom typing_extensions import TypedDict\n\n\n@data_source(\n  training_data=pd.read_csv(\n    'https://gist.githubusercontent.com/AlmogBaku/8be77c2236836177b8e54fa8217411f2/raw/hello_world_transactions.csv'),\n  production_config=StreamingConfig()\n)\nclass BankTransaction(TypedDict):\n  customer_id: str\n  amount: float\n  timestamp: str\n\n\n# Define features \ud83e\uddea\n@feature(keys='customer_id', data_source=BankTransaction)\n@aggregation(function=AggregationFunction.Sum, over='10h', granularity='1h')\ndef total_spend(this_row: BankTransaction, ctx: Context) -> float:\n  \"\"\"total spend by a customer in the last hour\"\"\"\n  return this_row['amount']\n\n\n@feature(keys='customer_id', data_source=BankTransaction)\n@freshness(max_age='5h', max_stale='1d')\ndef amount(this_row: BankTransaction, ctx: Context) -> float:\n  \"\"\"total spend by a customer in the last hour\"\"\"\n  return this_row['amount']\n\n\n# Train the model \ud83e\udd13\n@model(\n  keys='customer_id',\n  input_features=['total_spend+sum'],\n  input_labels=[amount],\n  model_framework='sklearn',\n  model_server='sagemaker-ack',\n)\n@freshness(max_age='1h', max_stale='100h')\ndef amount_prediction(ctx: TrainingContext):\n  from sklearn.linear_model import LinearRegression\n  df = ctx.features_and_labels()\n  trainer = LinearRegression()\n  trainer.fit(df[ctx.input_features], df[ctx.input_labels])\n  return trainer\n\n\namount_prediction.export()  # Export to production \ud83c\udf89\n")),(0,r.kt)("p",null,"That's it! You can now run the code, and it will export your work as production artifacts."),(0,r.kt)("p",null,"You can deliver these artifacts to your backend or devops engineers, and they can deploy them to production using\nstandard tools such as ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl")," or instruct them to plug in their CI/CD pipeline using the generated ",(0,r.kt)("inlineCode",{parentName:"p"},"Makefile"),"."),(0,r.kt)("h2",{id:"whats-next"},"What's next?"),(0,r.kt)("p",null,"To learn more about the full potential of Raptor, check out the ",(0,r.kt)("a",{parentName:"p",href:"/docs/concepts/"},"core concepts")," section or dig into the\nexpanded ",(0,r.kt)("a",{parentName:"p",href:"docs/getting-started-ipynb"},"Getting Started")," guide."))}u.isMDXComponent=!0}}]);